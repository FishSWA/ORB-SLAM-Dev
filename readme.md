## 简介
一个试图只依赖OpenCV实现双目VSLAM的学习项目，边学边写中，欢迎大家指点（

## 硬件依赖
- 一个双目相机，目前使用D430，但不依赖他内部的双目解算和结构光以及标定程序，可以替换成任意双目相机或者两个独立的摄像头
- 一个可靠的IMU，打算用自己画的LSM6D0+MMC5603 USB陀螺仪模块
- 一个支持OpenCL的GPU（打算使用opencl加速）

## 系统兼容
为了方便在我的各种设备上开发，会兼容以下的系统
- WSL2 (Ubuntu 2024.04)
- Macos（M1 macbookair）
- Ubuntu 2024.04（RK3588开发板）

## 计划的算法流程
1. 获取到可靠的ORB特征点点云
    - 提取orb特征点
    - 通过相关度和线性约束来匹配左右眼的特诊点
    - 三角测量得到特征点点云
2. 帧间相对位置推算 & 局部地图构建
    - 匹配帧间的特征点，推算出2帧之间相机的位置变化
    - 标记出两帧可以匹配上的特征点，构建局部地图
    - 剔除不可靠特征点（比如说镜面反光？）
3. 轨迹推算&当前位姿输出
    - 结合历史轨迹来计算当前最有可能的位姿
    - 融合IMU数据实现高速率的位姿输出
4. 闭环检测
5. 全局优化
## 关于优化
- OpenCV部分使用cv::UMat
- 自己写的算法，对性能影响非常大的部分手动调用OpenCL优化

## ChangeLog
**2024.10.31** 加入了imgui图形界面库
**2024.10.4** D430图像的读取
**2024.10.4** 新建文件夹